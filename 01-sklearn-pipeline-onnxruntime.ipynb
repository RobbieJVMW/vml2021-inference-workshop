{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "source": [
    "# Introduction and Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on http://onnx.ai/sklearn-onnx/auto_examples/plot_complex_pipeline.html with some code changes. \n",
    "\n",
    "For more examples about how to use ONNX and ONNX Runtime with classical classifiers with sklearn -- check out:\n",
    "\n",
    "http://onnx.ai/sklearn-onnx/auto_examples/index.html\n",
    "\n",
    "Workflow: \n",
    "\n",
    "1. Train a sklearn classifier with Pipeline\n",
    "2. Convert into ONNX format\n",
    "3. Use ONNX Runtime to do inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libaries \n",
    "You can skip installing the following packages if you're using container where all libaries are pre-installed. If not, you'll need to uncomment the cell and install the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip install skl2onnx\n",
    "# !pip install pandas\n",
    "# !pip install --upgrade onnxruntime==1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.testing import assert_almost_equal\n",
    "import onnxruntime as rt\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://www.kaggle.com/c/titanic/data\n",
    "data = pd.read_csv(\"datasets/titanic.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "print(data.dtypes)\n",
    "\n",
    "# SimpleImputer on string is not available for\n",
    "# string in ONNX-ML specifications.\n",
    "# So we do it beforehand.\n",
    "\n",
    "for cat in ['embarked', 'sex', 'pclass']:\n",
    "    X[cat].fillna('missing', inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    # --- SimpleImputer is not available for strings in ONNX-ML specifications.\n",
    "    # ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump(clf, open(\"models/pipeline_titanic.pkl\", 'wb'))\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the inputs of the ONNX graph\n",
    "\n",
    "*sklearn-onnx* does not know the features used to train the model\n",
    "but it needs to know which feature has which name.\n",
    "We simply reuse the dataframe column definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import skl2onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
    "from skl2onnx.common.data_types import Int64TensorType\n",
    "\n",
    "# Conversion of inputs to ONNX inputs \n",
    "def convert_dataframe_schema(df, drop=None):\n",
    "    inputs = []\n",
    "    for k, v in zip(df.columns, df.dtypes):\n",
    "        if drop is not None and k in drop:\n",
    "            continue\n",
    "        if v == 'int64':\n",
    "            t = Int64TensorType(shape=[None, 1])\n",
    "        elif v == 'float64':\n",
    "            t = FloatTensorType(shape=[None, 1])\n",
    "        else:\n",
    "            t = StringTensorType(shape=[None, 1])\n",
    "        inputs.append((k, t))\n",
    "    return inputs\n",
    "\n",
    "initial_inputs = convert_dataframe_schema(X_train)\n",
    "\n",
    "pprint.pprint(initial_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused inputs\n",
    "to_drop = {'parch', 'sibsp', 'cabin', 'ticket',\n",
    "           'name', 'body', 'home.dest', 'boat'}\n",
    "initial_inputs = convert_dataframe_schema(X_train, to_drop)\n",
    "pprint.pprint(initial_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pipeline into ONNX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`convert_sklearn` function produces an equivalent ONNX model of the given scikit-learn model.\n",
    "API reference: http://onnx.ai/sklearn-onnx/_modules/skl2onnx/convert.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "try:\n",
    "    model_onnx = convert_sklearn(model=clf, name='pipeline_titanic', initial_types=initial_inputs,\n",
    "                                 target_opset=12, verbose=2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# And save.\n",
    "with open(\"models/pipeline_titanic.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the predictions\n",
    "\n",
    "Final step, we need to ensure the converted model\n",
    "produces the same predictions, labels and probabilities.\n",
    "Let's start with *scikit-learn*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"predict\", clf.predict(X_test[:5]))\n",
    "print(\"predict_proba\", clf.predict_proba(X_test[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions with onnxruntime.\n",
    "We need to remove the dropped columns and to change\n",
    "the double vectors into float vectors as *onnxruntime*\n",
    "does not support double floats.\n",
    "*onnxruntime* does not accept *dataframe*.\n",
    "inputs must be given as a list of dictionary.\n",
    "Last detail, every column was described  not really as a vector\n",
    "but as a matrix of one column which explains the last line\n",
    "with the *reshape*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_test2 = X_test.drop(to_drop, axis=1)\n",
    "inputs = {c: X_test2[c].values for c in X_test2.columns}\n",
    "for c in numeric_features:\n",
    "    inputs[c] = inputs[c].astype(np.float32)\n",
    "for k in inputs:\n",
    "    inputs[k] = inputs[k].reshape((inputs[k].shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to run *onnxruntime*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"models/pipeline_titanic.onnx\")\n",
    "pred_onx = sess.run(None, inputs)\n",
    "print(\"predict\", pred_onx[0][:5])\n",
    "print(\"predict_proba\", pred_onx[1][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of onnxruntime is a list of dictionaries.\n",
    "Let's swith to an array but that requires to convert again with\n",
    "an additional option zipmap.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_onnx = convert_sklearn(clf, 'pipeline_titanic', initial_inputs,\n",
    "                             target_opset=12,\n",
    "                             options={id(clf): {'zipmap': False}})\n",
    "\n",
    "with open(\"models/pipeline_titanic_nozipmap.onnx\", \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\"models/pipeline_titanic_nozipmap.onnx\")\n",
    "pred_onx = sess.run(None, inputs)\n",
    "print(\"predict\", pred_onx[0][:5])\n",
    "print(\"predict_proba\", pred_onx[1][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check they are the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(clf.predict_proba(X_test), pred_onx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare size of models:\n",
    "print('Pickle model size (MB):', os.path.getsize(\"models/pipeline_titanic.pkl\")/(1024*1024))\n",
    "print('ONNX model size with zipmap (MB):', os.path.getsize(\"models/pipeline_titanic.onnx\")/(1024*1024))\n",
    "print('ONNX model size without zipmap (MB):', os.path.getsize(\"models/pipeline_titanic_nozipmap.onnx\")/(1024*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the ONNX graph\n",
    "\n",
    "Finally, let's see the graph converted with *sklearn-onnx*:\n",
    "https://netron.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ONNX model format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Preprocessing: load the ONNX model\n",
    "model_path = 'models/pipeline_titanic_nozipmap.onnx'\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# Check the model\n",
    "try:\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "except onnx.checker.ValidationError as e:\n",
    "    print('The model is invalid: %s' % e)\n",
    "else:\n",
    "    print('The model is valid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
